{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "train = pd.read_csv('../data/sensor/train.csv')\n",
    "test = pd.read_csv('../data/sensor/test.csv')\n",
    "train_labels = pd.read_csv(\"../data/sensor/train_labels.csv\")\n",
    "\n",
    "train = train.set_index([\"sequence\", \"subject\", \"step\"])\n",
    "test = test.set_index([\"sequence\", \"subject\", \"step\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After Reshape\n",
      "Shape of training set: (25968, 60, 13)\n",
      "Shape of test set: (12218, 60, 13)\n"
     ]
    }
   ],
   "source": [
    "features = [\"sensor_{:02d}\".format(i) for i in range(13)]\n",
    "input_size = train.shape[1]\n",
    "sequence_length = len(train.index.get_level_values(2).unique())\n",
    "\n",
    "# Scaling test and train\n",
    "scaler = StandardScaler()\n",
    "train = scaler.fit_transform(train)\n",
    "test = scaler.transform(test)\n",
    "\n",
    "# Reshaping:\n",
    "train = train.reshape(-1, sequence_length, input_size)\n",
    "test = test.reshape(-1, sequence_length, input_size)\n",
    "print(\"After Reshape\")\n",
    "print(\"Shape of training set: {}\".format(train.shape))\n",
    "print(\"Shape of test set: {}\".format(test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataloaders are created!\n"
     ]
    }
   ],
   "source": [
    "# Splitting train data set into train and validation sets\n",
    "# validation size is selected as 0.2\n",
    "t_X, v_X, t_y, v_y = train_test_split(train, train_labels.state, test_size=0.20,\n",
    "                                      shuffle=True, random_state=0)\n",
    "\n",
    "# Converting train, validation and test data into tensors\n",
    "train_X_tensor = torch.tensor(t_X).float()\n",
    "val_X_tensor = torch.tensor(v_X).float()\n",
    "test_tensor = torch.tensor(test).float()\n",
    "\n",
    "# Converting train and validation labels into tensors\n",
    "train_y_tensor = torch.tensor(t_y.values)\n",
    "val_y_tensor = torch.tensor(v_y.values)\n",
    "\n",
    "# Creating train and validation tensors\n",
    "train_tensor = TensorDataset(train_X_tensor, train_y_tensor)\n",
    "val_tensor = TensorDataset(val_X_tensor, val_y_tensor)\n",
    "\n",
    "# Defining the dataloaders\n",
    "dataloaders = dict()\n",
    "dataloaders[\"train\"] = DataLoader(train_tensor, batch_size=64, shuffle=True)\n",
    "dataloaders[\"val\"] = DataLoader(val_tensor, batch_size=32)\n",
    "dataloaders[\"test\"] = DataLoader(test_tensor, batch_size=32)\n",
    "print(\"Dataloaders are created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_sizes, seq_len, dropout=0.5, output_size=1):\n",
    "        super(RNN, self).__init__()\n",
    "        \n",
    "        # LSTM Layers\n",
    "        self.lstm_1 = nn.LSTM(input_size, hidden_sizes[0], num_layers=2,\n",
    "                            batch_first=True, bidirectional=True, dropout=dropout)\n",
    "        self.lstm_21 = nn.LSTM(2*hidden_sizes[0], hidden_sizes[1], num_layers=2,\n",
    "                             batch_first=True, bidirectional=True, dropout=dropout)\n",
    "        self.lstm_22 = nn.LSTM(input_size, hidden_sizes[1], num_layers=2,\n",
    "                             batch_first=True, bidirectional=True, dropout=dropout)\n",
    "        self.lstm_31 = nn.LSTM(2*hidden_sizes[1], hidden_sizes[2], num_layers=2,\n",
    "                             batch_first=True, bidirectional=True, dropout=dropout)\n",
    "        self.lstm_32 = nn.LSTM(4*hidden_sizes[1], hidden_sizes[2], num_layers=2,\n",
    "                             batch_first=True, bidirectional=True, dropout=dropout)\n",
    "        self.lstm_41 = nn.LSTM(2*hidden_sizes[2], hidden_sizes[3], num_layers=2,\n",
    "                             batch_first=True, bidirectional=True, dropout=dropout)\n",
    "        self.lstm_42 = nn.LSTM(4*hidden_sizes[2], hidden_sizes[3], num_layers=2,\n",
    "                             batch_first=True, bidirectional=True, dropout=dropout)\n",
    "        hidd = 2*hidden_sizes[0] + 4*(hidden_sizes[1]+hidden_sizes[2]+hidden_sizes[3])\n",
    "        self.lstm_5 = nn.LSTM(hidd, hidden_sizes[4], num_layers=2,\n",
    "                             batch_first=True, bidirectional=True, dropout=dropout)\n",
    "        \n",
    "        # Fully Connected Layer\n",
    "        self.fc = nn.Sequential(nn.Linear(2*hidden_sizes[4]*seq_len, 4096),\n",
    "                                nn.ReLU(inplace=True),\n",
    "                                nn.Dropout(p=dropout),\n",
    "                                nn.Linear(4096, 1024),\n",
    "                                nn.ReLU(inplace=True),\n",
    "                                nn.Dropout(p=dropout),\n",
    "                                nn.Linear(1024, output_size),\n",
    "                                nn.Sigmoid()\n",
    "                               )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # lstm layers:\n",
    "        x1, _ = self.lstm_1(x)\n",
    "        \n",
    "        x_x1, _ = self.lstm_21(x1)\n",
    "        x_x2, _ = self.lstm_22(x)\n",
    "        x2 = torch.cat([x_x1, x_x2], dim=2)\n",
    "        \n",
    "        x_x1, _ = self.lstm_31(x_x1)\n",
    "        x_x2, _ = self.lstm_32(x2)\n",
    "        x3 = torch.cat([x_x1, x_x2], dim=2)\n",
    "        \n",
    "        x_x1, _ = self.lstm_41(x_x1)\n",
    "        x_x2, _ = self.lstm_42(x3)\n",
    "        x4 = torch.cat([x_x1, x_x2], dim=2)\n",
    "        x = torch.cat([x1, x2, x3, x4], dim=2)\n",
    "        x, _ = self.lstm_5(x)\n",
    "        \n",
    "        # fully connected layers:\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/41..  Training Loss: 0.690..  Validation Loss: 0.680.. \n",
      "Epoch: 2/41..  Training Loss: 0.680..  Validation Loss: 0.686.. \n",
      "Epoch: 3/41..  Training Loss: 0.679..  Validation Loss: 0.681.. \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 25\u001b[0m\n\u001b[1;32m     23\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     24\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m---> 25\u001b[0m     train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m train_losses\u001b[38;5;241m.\u001b[39mappend(train_loss\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mlen\u001b[39m(dataloaders[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m]))\n\u001b[1;32m     28\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "hidden_sizes = [288, 192, 144, 96, 32]\n",
    "max_learning_rate = 0.001\n",
    "epochs = 41\n",
    "model = RNN(input_size, hidden_sizes, sequence_length)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=max_learning_rate)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "for epoch in range(epochs):\n",
    "    train_loss = 0\n",
    "    val_loss = 0\n",
    "    model.train()\n",
    "    for inputs, labels in dataloaders[\"train\"]:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        labels = labels.unsqueeze(1).float()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(inputs)\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "    train_losses.append(train_loss/len(dataloaders[\"train\"]))\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloaders[\"val\"]:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            output = model(inputs)\n",
    "            loss = criterion(output.squeeze(), labels.float())\n",
    "            val_loss += loss.item()\n",
    "        val_losses.append(val_loss/len(dataloaders[\"val\"]))\n",
    "    \n",
    "    print(\"Epoch: {}/{}.. \".format(epoch+1, epochs),\n",
    "          \"Training Loss: {:.3f}.. \".format(train_losses[-1]),\n",
    "          \"Validation Loss: {:.3f}.. \".format(val_losses[-1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
