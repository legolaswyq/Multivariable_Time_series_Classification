{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "train = pd.read_csv('../data/sensor/train.csv')\n",
    "test = pd.read_csv('../data/sensor/test.csv')\n",
    "train_labels = pd.read_csv(\"../data/sensor/train_labels.csv\")\n",
    "\n",
    "train = train.set_index([\"sequence\", \"subject\", \"step\"])\n",
    "test = test.set_index([\"sequence\", \"subject\", \"step\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking if there are any missing values:\n",
      "Train: 0\n",
      "Test: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"Checking if there are any missing values:\")\n",
    "print(\"Train: {}\".format(train.isnull().sum().sum()))\n",
    "print(\"Test: {}\".format(test.isnull().sum().sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>sensor_00</th>\n",
       "      <th>sensor_01</th>\n",
       "      <th>sensor_02</th>\n",
       "      <th>sensor_03</th>\n",
       "      <th>sensor_04</th>\n",
       "      <th>sensor_05</th>\n",
       "      <th>sensor_06</th>\n",
       "      <th>sensor_07</th>\n",
       "      <th>sensor_08</th>\n",
       "      <th>sensor_09</th>\n",
       "      <th>sensor_10</th>\n",
       "      <th>sensor_11</th>\n",
       "      <th>sensor_12</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sequence</th>\n",
       "      <th>subject</th>\n",
       "      <th>step</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">0</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">47</th>\n",
       "      <th>0</th>\n",
       "      <td>-0.196291</td>\n",
       "      <td>0.112395</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.329204</td>\n",
       "      <td>-1.004660</td>\n",
       "      <td>-0.131638</td>\n",
       "      <td>-0.127505</td>\n",
       "      <td>0.368702</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-0.963873</td>\n",
       "      <td>-0.985069</td>\n",
       "      <td>0.531893</td>\n",
       "      <td>4.751492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.447450</td>\n",
       "      <td>0.134454</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.658407</td>\n",
       "      <td>0.162495</td>\n",
       "      <td>0.340314</td>\n",
       "      <td>-0.209472</td>\n",
       "      <td>-0.867176</td>\n",
       "      <td>0.2</td>\n",
       "      <td>-0.301301</td>\n",
       "      <td>0.082733</td>\n",
       "      <td>-0.231481</td>\n",
       "      <td>0.454390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.326893</td>\n",
       "      <td>-0.694328</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.330088</td>\n",
       "      <td>0.473678</td>\n",
       "      <td>1.280479</td>\n",
       "      <td>-0.094718</td>\n",
       "      <td>0.535878</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.002168</td>\n",
       "      <td>0.449221</td>\n",
       "      <td>-0.586420</td>\n",
       "      <td>-4.736147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.523184</td>\n",
       "      <td>0.751050</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.976991</td>\n",
       "      <td>-0.563287</td>\n",
       "      <td>-0.720269</td>\n",
       "      <td>0.793260</td>\n",
       "      <td>0.951145</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>-0.995665</td>\n",
       "      <td>-0.434290</td>\n",
       "      <td>1.344650</td>\n",
       "      <td>0.429241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.272025</td>\n",
       "      <td>1.074580</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.136283</td>\n",
       "      <td>0.398579</td>\n",
       "      <td>0.044877</td>\n",
       "      <td>0.560109</td>\n",
       "      <td>-0.541985</td>\n",
       "      <td>-0.9</td>\n",
       "      <td>1.055636</td>\n",
       "      <td>0.812631</td>\n",
       "      <td>0.123457</td>\n",
       "      <td>-0.223359</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       sensor_00  sensor_01  sensor_02  sensor_03  sensor_04  \\\n",
       "sequence subject step                                                          \n",
       "0        47      0     -0.196291   0.112395        1.0   0.329204  -1.004660   \n",
       "                 1     -0.447450   0.134454        1.0  -0.658407   0.162495   \n",
       "                 2      0.326893  -0.694328        1.0   0.330088   0.473678   \n",
       "                 3      0.523184   0.751050        1.0   0.976991  -0.563287   \n",
       "                 4      0.272025   1.074580        1.0  -0.136283   0.398579   \n",
       "\n",
       "                       sensor_05  sensor_06  sensor_07  sensor_08  sensor_09  \\\n",
       "sequence subject step                                                          \n",
       "0        47      0     -0.131638  -0.127505   0.368702       -0.1  -0.963873   \n",
       "                 1      0.340314  -0.209472  -0.867176        0.2  -0.301301   \n",
       "                 2      1.280479  -0.094718   0.535878        1.4   1.002168   \n",
       "                 3     -0.720269   0.793260   0.951145       -0.3  -0.995665   \n",
       "                 4      0.044877   0.560109  -0.541985       -0.9   1.055636   \n",
       "\n",
       "                       sensor_10  sensor_11  sensor_12  \n",
       "sequence subject step                                   \n",
       "0        47      0     -0.985069   0.531893   4.751492  \n",
       "                 1      0.082733  -0.231481   0.454390  \n",
       "                 2      0.449221  -0.586420  -4.736147  \n",
       "                 3     -0.434290   1.344650   0.429241  \n",
       "                 4      0.812631   0.123457  -0.223359  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def add_features(df, features):\n",
    "    for feature in features:\n",
    "        df_grouped = df.groupby(\"sequence\")[feature]\n",
    "        df_rolling = df_grouped.rolling(5, center=True)\n",
    "        \n",
    "        df[feature + \"_lag1\"] = df_grouped.shift(1)\n",
    "        df[feature + \"_diff1\"] = df[feature] - df[feature + \"_lag1\"]\n",
    "        df[feature + \"_lag2\"] = df_grouped.shift(2)\n",
    "        df[feature + \"_diff2\"] = df[feature] - df[feature + \"_lag2\"]\n",
    "        df[feature + \"_roll_mean\"] = df_rolling.mean().reset_index(0, drop=True)\n",
    "        df[feature + \"_roll_std\"] = df_rolling.std().reset_index(0, drop=True)\n",
    "    df.dropna(axis=0, inplace=True)\n",
    "    return\n",
    "\n",
    "features = [\"sensor_{:02d}\".format(i) for i in range(13)]\n",
    "# add_features(train, features)\n",
    "# add_features(test, features)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After Reshape\n",
      "Shape of training set: (25968, 60, 13)\n",
      "Shape of test set: (12218, 60, 13)\n"
     ]
    }
   ],
   "source": [
    "input_size = train.shape[1]\n",
    "sequence_length = len(train.index.get_level_values(2).unique())\n",
    "\n",
    "# Scaling test and train\n",
    "scaler = StandardScaler()\n",
    "train = scaler.fit_transform(train)\n",
    "test = scaler.transform(test)\n",
    "\n",
    "# Reshaping:\n",
    "train = train.reshape(-1, sequence_length, input_size)\n",
    "test = test.reshape(-1, sequence_length, input_size)\n",
    "print(\"After Reshape\")\n",
    "print(\"Shape of training set: {}\".format(train.shape))\n",
    "print(\"Shape of test set: {}\".format(test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataloaders are created!\n"
     ]
    }
   ],
   "source": [
    "# Splitting train data set into train and validation sets\n",
    "# validation size is selected as 0.2\n",
    "t_X, v_X, t_y, v_y = train_test_split(train, train_labels.state, test_size=0.20,\n",
    "                                      shuffle=True, random_state=0)\n",
    "\n",
    "# Converting train, validation and test data into tensors\n",
    "train_X_tensor = torch.tensor(t_X).float()\n",
    "val_X_tensor = torch.tensor(v_X).float()\n",
    "test_tensor = torch.tensor(test).float()\n",
    "\n",
    "# Converting train and validation labels into tensors\n",
    "train_y_tensor = torch.tensor(t_y.values)\n",
    "val_y_tensor = torch.tensor(v_y.values)\n",
    "\n",
    "# Creating train and validation tensors\n",
    "train_tensor = TensorDataset(train_X_tensor, train_y_tensor)\n",
    "val_tensor = TensorDataset(val_X_tensor, val_y_tensor)\n",
    "\n",
    "# Defining the dataloaders\n",
    "dataloaders = dict()\n",
    "dataloaders[\"train\"] = DataLoader(train_tensor, batch_size=64, shuffle=True)\n",
    "dataloaders[\"val\"] = DataLoader(val_tensor, batch_size=32)\n",
    "dataloaders[\"test\"] = DataLoader(test_tensor, batch_size=32)\n",
    "print(\"Dataloaders are created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition of a RNN Model class\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_sizes, seq_len, dropout=0.5, output_size=1):\n",
    "        super(RNN, self).__init__()\n",
    "        \n",
    "        # LSTM Layers\n",
    "        self.lstm_1 = nn.LSTM(input_size, hidden_sizes[0], num_layers=2,\n",
    "                            batch_first=True, bidirectional=True, dropout=dropout)\n",
    "        self.lstm_21 = nn.LSTM(2*hidden_sizes[0], hidden_sizes[1], num_layers=2,\n",
    "                             batch_first=True, bidirectional=True, dropout=dropout)\n",
    "        self.lstm_22 = nn.LSTM(input_size, hidden_sizes[1], num_layers=2,\n",
    "                             batch_first=True, bidirectional=True, dropout=dropout)\n",
    "        self.lstm_31 = nn.LSTM(2*hidden_sizes[1], hidden_sizes[2], num_layers=2,\n",
    "                             batch_first=True, bidirectional=True, dropout=dropout)\n",
    "        self.lstm_32 = nn.LSTM(4*hidden_sizes[1], hidden_sizes[2], num_layers=2,\n",
    "                             batch_first=True, bidirectional=True, dropout=dropout)\n",
    "        self.lstm_41 = nn.LSTM(2*hidden_sizes[2], hidden_sizes[3], num_layers=2,\n",
    "                             batch_first=True, bidirectional=True, dropout=dropout)\n",
    "        self.lstm_42 = nn.LSTM(4*hidden_sizes[2], hidden_sizes[3], num_layers=2,\n",
    "                             batch_first=True, bidirectional=True, dropout=dropout)\n",
    "        hidd = 2*hidden_sizes[0] + 4*(hidden_sizes[1]+hidden_sizes[2]+hidden_sizes[3])\n",
    "        self.lstm_5 = nn.LSTM(hidd, hidden_sizes[4], num_layers=2,\n",
    "                             batch_first=True, bidirectional=True, dropout=dropout)\n",
    "        \n",
    "        # Fully Connected Layer\n",
    "        self.fc = nn.Sequential(nn.Linear(2*hidden_sizes[4]*seq_len, 4096),\n",
    "                                nn.ReLU(inplace=True),\n",
    "                                nn.Dropout(p=dropout),\n",
    "                                nn.Linear(4096, 1024),\n",
    "                                nn.ReLU(inplace=True),\n",
    "                                nn.Dropout(p=dropout),\n",
    "                                nn.Linear(1024, output_size),\n",
    "                                nn.Sigmoid()\n",
    "                               )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # lstm layers:\n",
    "        x1, _ = self.lstm_1(x)\n",
    "        \n",
    "        x_x1, _ = self.lstm_21(x1)\n",
    "        x_x2, _ = self.lstm_22(x)\n",
    "        x2 = torch.cat([x_x1, x_x2], dim=2)\n",
    "        \n",
    "        x_x1, _ = self.lstm_31(x_x1)\n",
    "        x_x2, _ = self.lstm_32(x2)\n",
    "        x3 = torch.cat([x_x1, x_x2], dim=2)\n",
    "        \n",
    "        x_x1, _ = self.lstm_41(x_x1)\n",
    "        x_x2, _ = self.lstm_42(x3)\n",
    "        x4 = torch.cat([x_x1, x_x2], dim=2)\n",
    "        x = torch.cat([x1, x2, x3, x4], dim=2)\n",
    "        x, _ = self.lstm_5(x)\n",
    "        \n",
    "        # fully connected layers:\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "### VALIDATION FUNCTION\n",
    "def validation(model, loader, criterion, device=\"cpu\"):\n",
    "    model.eval()\n",
    "    loss = 0\n",
    "    preds_all = torch.LongTensor()\n",
    "    labels_all = torch.LongTensor()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_x, labels in loader:\n",
    "            labels_all = torch.cat((labels_all, labels), dim=0)\n",
    "            batch_x, labels = batch_x.to(device), labels.to(device)\n",
    "            labels = labels.unsqueeze(1).float()\n",
    "            \n",
    "            output = model.forward(batch_x)\n",
    "            loss += criterion(output,labels).item()\n",
    "            preds_all = torch.cat((preds_all, output.to(\"cpu\")), dim=0)\n",
    "    total_loss = loss/len(loader)\n",
    "    auc_score = roc_auc_score(labels_all, preds_all)\n",
    "    return total_loss, auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TRAINING FUNCTION\n",
    "def train_model(model, trainloader, validloader, criterion, optimizer, \n",
    "                scheduler, epochs=20, device=\"cpu\", print_every=1):\n",
    "    model.to(device)\n",
    "    best_auc = 0\n",
    "    best_epoch = 0\n",
    "    for e in range(epochs):\n",
    "        model.train()\n",
    "        \n",
    "        for batch_x, labels in trainloader:\n",
    "            batch_x, labels = batch_x.to(device), labels.to(device)\n",
    "            labels = labels.unsqueeze(1).float()\n",
    "            \n",
    "            # Training \n",
    "            optimizer.zero_grad()\n",
    "            output = model.forward(batch_x)\n",
    "            loss = criterion(output, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "        # at the end of each epoch calculate loss and auc score:\n",
    "        model.eval()\n",
    "        train_loss, train_auc = validation(model, trainloader, criterion, device)\n",
    "        valid_loss, valid_auc = validation(model, validloader, criterion, device)\n",
    "        if valid_auc > best_auc:\n",
    "            best_auc = valid_auc\n",
    "            best_epoch = e\n",
    "            torch.save(model.state_dict(), \"best-state.pt\")\n",
    "        if e % print_every == 0:\n",
    "            to_print = \"Epoch: \"+str(e+1)+\" of \"+str(epochs)\n",
    "            to_print += \".. Train Loss: {:.4f}\".format(train_loss)\n",
    "            to_print += \".. Valid Loss: {:.4f}\".format(valid_loss)\n",
    "            to_print += \".. Valid AUC: {:.3f}\".format(valid_auc)\n",
    "            print(to_print)\n",
    "    # After Training:\n",
    "    model.load_state_dict(torch.load(\"best-state.pt\"))\n",
    "    to_print = \"\\nTraining completed. Best state dict is loaded.\\n\"\n",
    "    to_print += \"Best Valid AUC is: {:.4f} after {} epochs\".format(best_auc,best_epoch+1)\n",
    "    print(to_print)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "### PREDICTION FUNCTION\n",
    "def prediction(model, loader, device=\"cpu\"):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    preds_all = torch.LongTensor()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_x in loader:\n",
    "            batch_x = batch_x.to(device)\n",
    "            \n",
    "            output = model.forward(batch_x).to(\"cpu\")\n",
    "            preds_all = torch.cat((preds_all, output), dim=0)\n",
    "    return preds_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 [288, 192, 144, 96, 32] 60\n",
      "Model: \n",
      "RNN(\n",
      "  (lstm_1): LSTM(13, 288, num_layers=2, batch_first=True, dropout=0.5, bidirectional=True)\n",
      "  (lstm_21): LSTM(576, 192, num_layers=2, batch_first=True, dropout=0.5, bidirectional=True)\n",
      "  (lstm_22): LSTM(13, 192, num_layers=2, batch_first=True, dropout=0.5, bidirectional=True)\n",
      "  (lstm_31): LSTM(384, 144, num_layers=2, batch_first=True, dropout=0.5, bidirectional=True)\n",
      "  (lstm_32): LSTM(768, 144, num_layers=2, batch_first=True, dropout=0.5, bidirectional=True)\n",
      "  (lstm_41): LSTM(288, 96, num_layers=2, batch_first=True, dropout=0.5, bidirectional=True)\n",
      "  (lstm_42): LSTM(576, 96, num_layers=2, batch_first=True, dropout=0.5, bidirectional=True)\n",
      "  (lstm_5): LSTM(2304, 32, num_layers=2, batch_first=True, dropout=0.5, bidirectional=True)\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=3840, out_features=4096, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "    (3): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): Dropout(p=0.5, inplace=False)\n",
      "    (6): Linear(in_features=1024, out_features=1, bias=True)\n",
      "    (7): Sigmoid()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "hidden_sizes = [288, 192, 144, 96, 32]\n",
    "max_learning_rate = 0.001\n",
    "epochs = 41\n",
    "\n",
    "# Model\n",
    "print(input_size, hidden_sizes, sequence_length)\n",
    "model_lstm = RNN(input_size, hidden_sizes, sequence_length)\n",
    "print(\"Model: \")\n",
    "print(model_lstm)\n",
    "\n",
    "# criterion, optimizer, scheduler\n",
    "#criterion = nn.MSELoss()\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model_lstm.parameters(), lr=max_learning_rate)\n",
    "scheduler = optim.lr_scheduler.OneCycleLR(optimizer,\n",
    "                                          max_lr = max_learning_rate,\n",
    "                                          epochs = epochs,\n",
    "                                          steps_per_epoch = len(dataloaders[\"train\"]),\n",
    "                                          pct_start = 0.2,\n",
    "                                          anneal_strategy = \"cos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is enabled\n",
      "Epoch: 1/41..  Training Loss: 0.684..  Validation Loss: 0.681..  Validation AUC: 0.588\n",
      "Epoch: 2/41..  Training Loss: 0.662..  Validation Loss: 0.640..  Validation AUC: 0.714\n",
      "Epoch: 3/41..  Training Loss: 0.586..  Validation Loss: 0.531..  Validation AUC: 0.812\n",
      "Epoch: 4/41..  Training Loss: 0.515..  Validation Loss: 0.472..  Validation AUC: 0.858\n",
      "Epoch: 5/41..  Training Loss: 0.476..  Validation Loss: 0.448..  Validation AUC: 0.875\n",
      "Epoch: 6/41..  Training Loss: 0.447..  Validation Loss: 0.422..  Validation AUC: 0.888\n",
      "Epoch: 7/41..  Training Loss: 0.430..  Validation Loss: 0.405..  Validation AUC: 0.897\n",
      "Epoch: 8/41..  Training Loss: 0.418..  Validation Loss: 0.401..  Validation AUC: 0.899\n",
      "Epoch: 9/41..  Training Loss: 0.408..  Validation Loss: 0.401..  Validation AUC: 0.900\n",
      "Epoch: 10/41..  Training Loss: 0.401..  Validation Loss: 0.408..  Validation AUC: 0.904\n",
      "Epoch: 11/41..  Training Loss: 0.400..  Validation Loss: 0.421..  Validation AUC: 0.900\n",
      "Epoch: 12/41..  Training Loss: 0.383..  Validation Loss: 0.402..  Validation AUC: 0.901\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 25\u001b[0m\n\u001b[1;32m     23\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     24\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m---> 25\u001b[0m     train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m train_losses\u001b[38;5;241m.\u001b[39mappend(train_loss\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mlen\u001b[39m(dataloaders[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m]))\n\u001b[1;32m     28\u001b[0m model_lstm\u001b[38;5;241m.\u001b[39meval()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Checking if GPU is available\n",
    "if torch.cuda.is_available():\n",
    "    my_device = \"cuda\"\n",
    "    print(\"GPU is enabled\")\n",
    "else:\n",
    "    my_device = \"cpu\"\n",
    "    print(\"No GPU :(\")\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "model_lstm.to(my_device)\n",
    "for epoch in range(epochs):\n",
    "    train_loss = 0\n",
    "    val_loss = 0\n",
    "    model_lstm.train()\n",
    "    for inputs, labels in dataloaders[\"train\"]:\n",
    "        inputs, labels = inputs.to(my_device), labels.to(my_device)\n",
    "        labels = labels.unsqueeze(1).float()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model_lstm(inputs)\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "    train_losses.append(train_loss/len(dataloaders[\"train\"]))\n",
    "    \n",
    "    model_lstm.eval()\n",
    "    preds_all = torch.LongTensor()\n",
    "    labels_all = torch.LongTensor()\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloaders[\"val\"]:\n",
    "            inputs, labels = inputs.to(my_device), labels.to(my_device)\n",
    "            output = model_lstm(inputs)\n",
    "            preds_all = torch.cat((preds_all, output.to(\"cpu\")), dim=0)\n",
    "            labels_all = torch.cat((labels_all, labels.to(\"cpu\")), dim=0)\n",
    "            loss = criterion(output.squeeze(), labels.float())\n",
    "            val_loss += loss.item()\n",
    "        val_losses.append(val_loss/len(dataloaders[\"val\"]))\n",
    "        \n",
    "        auc_score = roc_auc_score(labels_all, preds_all)\n",
    "    print(\"Epoch: {}/{}.. \".format(epoch+1, epochs),\n",
    "          \"Training Loss: {:.3f}.. \".format(train_losses[-1]),\n",
    "          \"Validation Loss: {:.3f}.. \".format(val_losses[-1]),\n",
    "          \"Validation AUC: {:.3f}\".format(auc_score))\n",
    "\n",
    "# Training\n",
    "# train_model(model = model_lstm,\n",
    "#             trainloader = dataloaders[\"train\"],\n",
    "#             validloader = dataloaders[\"val\"],\n",
    "#             criterion = criterion,\n",
    "#             optimizer = optimizer,\n",
    "#             scheduler = scheduler,\n",
    "#             epochs = epochs,\n",
    "#             device = my_device,\n",
    "#             print_every = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction completed, first 5 states:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.9915],\n",
       "        [0.9708],\n",
       "        [0.0377],\n",
       "        [0.9311],\n",
       "        [0.6453]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = prediction(model_lstm, dataloaders[\"test\"], device=my_device)\n",
    "print(\"Prediction completed, first 5 states:\")\n",
    "y_pred[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25968</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25969</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25970</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25971</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25972</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sequence  state\n",
       "0     25968    1.0\n",
       "1     25969    1.0\n",
       "2     25970    0.0\n",
       "3     25971    1.0\n",
       "4     25972    1.0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.read_csv(\"../data/sensor/sample_submission.csv\")\n",
    "submission.state = torch.round(y_pred)\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resuls are saved to submission.csv\n"
     ]
    }
   ],
   "source": [
    "submission.to_csv('submission.csv', index=False)\n",
    "print(\"Resuls are saved to submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
